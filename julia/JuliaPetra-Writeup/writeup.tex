\documentclass[acmsmall]{acmart}
\bibliographystyle{ACM-Reference-Format}

\usepackage{array}
\usepackage{tikz}
\usetikzlibrary{positioning} 

\title{JuliaPetra: An Implementation of the Petra Object Model in Julia}

\author{Neil Lindquist}
\email{neillindquist5@gmail.com}

\acmJournal{TOMS}


\newcommand{\juliaSnippet}[1]{\texttt{\detokenize{#1}}}

\begin{document}

\maketitle

%TODO improve use of transitions between sentences
%TODO improve inter-paragraph and inter-sectional transitioning

\section{Introduction}

%REVIEW should there be a intro paragraph before the petra object model?

%TODO go into more detail?
	%I'm not sure what detail to discuss
	%This paragraph seems to short currently
The Petra Object Model is the design used in Trilinos for objects commonly used in solver algorithms.
\cite{OverviewOfTrilinos}
Petra libraries provide parallel, distributed matrices, vectors and graphs for other packages to use.
The Petra object model has previously been implemented in both C++ and Java.
%REVIEW should this list of previous implemenetations be in the paper?

Julia is a programing language that uses just in time compiling and strong type inferencing
to obtain the speed of a statically compiled programing language with the productivity of an
interpreted programing language. \cite{JuliaFreshApproach}
By providing speed comparable to that of Fortran or C, Julia is a candidate for doing large scale,
high performance computations.
The Celeste project is an example of such computations, using 8,192 cores of the Cori Supercomputer
at Lawrence Berkeley National Laboratory.
%REVIEW does Celeste need to be cited seperately?  Its mentioned in JuliaFreshApproach

JuliaPetra is an implementation of the Petra object model in Julia.
This provides Petra's distributed linear algebra objects for use in Julia implementations
of distributed solver algorithms.
%REVIEW I'm not liking the preceding sentence
JuliaPetra provides the ability to do basic linear algebra computations
such as dot products, vector norms and sparse matrix - vector multiplications.
%REVIEW should it go into more detail of possible compuations?

\section{Design of JuliaPetra}

\begin{figure}
	%name, type, location
	\newcommand{\typeNode} [3]{\node[#2] (#1) [#3] {\juliaSnippet{#1}};}
	\newcommand{\explicitInheritance}[2]{\draw[->] (#1.south) -- (#2);}
	\newcommand{\implicitInheritance}[2]{\draw[dashed,->] (#1.south) -- (#2);}
	\begin{tikzpicture}[
		ImplicitInterface/.style={rectangle, draw=black, dashed, minimum size=5mm},
		ExplicitInterface/.style={rectangle, draw=black, minimum size=5mm},
		ConcreteType/.style={rectangle, draw=black, very thick, minimum size=5mm}
		]
		
		\typeNode{Comm}{ExplicitInterface}{}
		
		\typeNode{MPIComm}{ConcreteType}{below=.75cm of Comm}
		\explicitInheritance{Comm}{MPIComm.north}
		
		\typeNode{SerialComm}{ConcreteType}{right=.25cm of MPIComm}
		\explicitInheritance{Comm}{SerialComm.north}
		
		\typeNode{LocalComm}{ConcreteType}{left=.25cm of MPIComm}
		\explicitInheritance{Comm}{LocalComm.north}
		
		\typeNode{Distributor}{ExplicitInterface}{left=5.1cm of Comm}
		
		\typeNode{SerialDistributor}{ConcreteType}{below right=.75cm and -1cm of Distributor}
		\explicitInheritance{Distributor}{SerialDistributor.north}
		
		\typeNode{MPIDistributor}{ConcreteType}{left=.25cm of SerialDistributor}
		\explicitInheritance{Distributor}{MPIDistributor.north}
		
		
		
		\typeNode{Directory}{ExplicitInterface}{below right=.75cm and -1.25cm of MPIDistributor}
		
		\typeNode{BasicDirectory}{ConcreteType}{below=.75cm of Directory}
		\explicitInheritance{Directory}{BasicDirectory.north}
		
		\typeNode{BlockMap}{ConcreteType}{right=of Directory}
		
		\typeNode{Import}{ConcreteType}{right=of BlockMap}
		
		\typeNode{Export}{ConcreteType}{right=of Import}
		
		
		
		\typeNode{SrcDistObject}{ImplicitInterface}{below left=.75cm and -.9cm of Export}
		
		\typeNode{DistObject}{ImplicitInterface}{below=.75cm of SrcDistObject}
		\implicitInheritance{SrcDistObject}{DistObject.north}
		
		\typeNode{Operator}{ImplicitInterface}{left=of DistObject}
		
		\typeNode{AbstractArray}{ExplicitInterface}{left=of Operator}
		
		\typeNode{MultiVector}{ConcreteType}{below=of AbstractArray}
		\implicitInheritance{DistObject}{MultiVector.north east}
		\explicitInheritance{AbstractArray}{MultiVector.north}
		
		\typeNode{RowMatrix}{ExplicitInterface}{below=of Operator}
		\implicitInheritance{DistObject}{RowMatrix.north east}
		\implicitInheritance{Operator}{RowMatrix.north}
		\explicitInheritance{AbstractArray}{RowMatrix.north west}
		
		\typeNode{RowGraph}{ExplicitInterface}{below=of DistObject}
		\implicitInheritance{DistObject}{RowGraph.north}
		
		\typeNode{CSRMatrix}{ConcreteType}{below=.75cm of RowMatrix}
		\explicitInheritance{RowMatrix}{CSRMatrix.north}
		
		\typeNode{CSRGraph}{ConcreteType}{below=.75cm of RowGraph}
		\explicitInheritance{RowGraph}{CSRGraph.north}
		
		
		
		\node[ExplicitInterface] (ExplicitKey) [below=of CSRMatrix] {Abstract Type};
		\node[ImplicitInterface] (ImplicitKey) [left=of ExplicitKey] {Implicit Type};
		\node[ConcreteType]      (ConcreteKey) [right=of ExplicitKey] {Concrete Type};

	\end{tikzpicture}
	\caption{Type hierarchy.}
	\label{fig:type-hierarchy}
\end{figure}

The design of JuliaPetra follows closely with that of the C++ implementations of the
Petra object model, Epetra and Tpetra.
In particular, the communication APIs, such as \juliaSnippet{Comm} and \juliaSnippet{BlockMap},
are based directly off Epetra, while the data structures, such as \juliaSnippet{MultiVector} and
\juliaSnippet{RowMatrix}, are based directly off Tpetra.
Additionally, like Epetra and Tpetra, JuliaPetra uses MPI and Single-Program-Multiple-Data as it's parallel model.

The bottom level of abstraction handles the details of how the problem is distributed across processes.
The \juliaSnippet{Comm} and \juliaSnippet{Distributor} types provide an interface to support
different communication methods.
All interprocess communication is done through \juliaSnippet{Comm} and \juliaSnippet{Distributor} objects.
So new communication systems can be implemented without affected the objects built on top of it.
The \juliaSnippet{BlockMap}, \juliaSnippet{Directory}, \juliaSnippet{Import} and \juliaSnippet{Export}
types handle the next layer of abstraction.
\juliaSnippet{BlockMap} and \juliaSnippet{Directory} manage where the various indices of the problem are located.
\juliaSnippet{Import} and \juliaSnippet{Export} handle the logic behind redistributing the indices of
the problem between processes.
The \juliaSnippet{SrcDistObject} and \juliaSnippet{DistObject} interfaces provide the necessary
methods for handling the actual redistribution of the data in the various data structures.
This communication layer provides an abstraction on which the data structures can build.

The linear algebra objects are built on top of the abstractions provided by the communication layer.
JuliaPetra has three main linear algebra types.
The first type is the concrete type \juliaSnippet{MultiVector} which holds one or more dense vectors.
The second type is the abstract interface \juliaSnippet{RowMatrix} representing matrices accessed by rows.
Vectors and row matrices are used to store their respective linear algebra data types.
The last type is the abstract interface \juliaSnippet{RowGraph} representing graphs accessed by rows.
Row graphs are mainly used to represent the sparsity pattern of row matrices.
Both \juliaSnippet{RowGraph} and \juliaSnippet{RowMatrix} have concrete implementations based on
compressed sparse row format, \juliaSnippet{CSRGraph} and \juliaSnippet{CSRMatrix} respectively.
Julia's \juliaSnippet{AbstractArray} is subtyped by both the \juliaSnippet{MultiVector}
and \juliaSnippet{RowMatrix} types to allow existing Julia code to interact with data in JuliaPetra objects.
The \juliaSnippet{Operator} interface can be implemented by types that provide an
\(y = \alpha A x + \beta y\) operation, such as matrices.
\juliaSnippet{RowMatrix} is the only implementation of \juliaSnippet{Operator} in JuliaPetra.

The type hierarchy is limited by the fact that Julia doesn't support multiple inheritance.  %TODO cite?
Interacting with existing code as a 2-dimensional array requires being a subtype of \juliaSnippet{AbstractArray}.
So, the other interfaces for the data structures are not explicit types,
but simply contracts promised in the documentation.
These interfaces include \juliaSnippet{Operator}, \juliaSnippet{SrcDistObject} and \juliaSnippet{DistObject}.
So, any methods that use one of those types accepts any object and assumes the methods required for the interface are present.
Figure~\ref{fig:type-hierarchy} contains the full type hierarchy.

\section{Comparisons with Other Distributed Libraries}

\subsection{Comparing with Epetra}

Epetra is the base implementation of the Petra object model,
written in a stable subset of C++. \cite{OverviewOfTrilinos}
Because Epetra was used as the template for implementing JuliaPetra,
the APIs for JuliaPetra are similar to those for Epetra.
The similarities between JuliaPetra and Epetra can be seen in how similar the respective implementations
of the power method are.
The differences in features between the implementation languages result in differences
between JuliaPetra's and Epetra's APIs.
For example, JuliaPetra takes advantage of higher level structures
such as type templating and thrown exceptions.

JuliaPetra was able to achieve the same performance as Epetra on large instances of the power method,
as shown in Table~\ref{tab:timing-results}.
Since Julia uses just in time compiling exclusively, it has extra start up costs compared to
the Epetra version. However, since each specialized method needs to be compiled only once,
this is a fixed cost.
Additionally, JuliaPetra uses runtime dispatch in a few locations, such as with
\juliaSnippet{Comm} objects, which adds additional overhead compared to Epetra.

\subsection{Comparing with DistributedArrays.jl}

DistributedArrays.jl is a similar library to JuliaPetra that is designed to support
distributed arrays in parallel environments. \cite{DAGithub}
DistributedArrays.jl is designed for Julia's built in model for parallelism, where the program logic is
contained in a master process that allocates work to the worker processes for expensive operations.
\cite{JuliaFreshApproach}
DistributedArrays.jl offers a number of advantages over JuliaPetra, however, it is not able to
match the speed of JuliaPetra.

DistributedArrays.jl has advantages over JuliaPetra because it is better designed to function with
existing Julia code.
For example, it is built around the default Julia parallelization APIs and model as well as using
Julia \juliaSnippet{AbstractArray}s for local storage.
Another advantage is that DistributedArrays.jl uses an instance of \juliaSnippet{AbstractArray}
for a process's local storage, this allows automatic support for different array structures.
Finally, by keeping the program logic on the master process, DistributedArrays.jl can be used to
do distributed computations while using Julia's read-eval-print loop.

However, DistributedArrays.jl was not able to match the speed of JuliaPetra.
JuliaPetra was able to run within half of the execution time of DistributedArrays.jl.
The difference in time is caused by JuliaPetra needing less inter-process communication.
%TODO is there other sources of improvement?

\section{Results}

\begin{table}
\begin{tabular}{|c c|r|r|r||r|r|}
	\hline
		\multicolumn{2}{|c|}{Equations Per Process}
		& JuliaPetra
		& Epetra
		& \multicolumn{1}{m{1.8cm}||}{Distributed\-Arrays.jl}
		& \multicolumn{1}{m{1.75cm}|}{JuliaPetra / Epetra}
		& \multicolumn{1}{m{1.8cm}|}{JuliaPetra / Distributed\-Arrays.jl} \\
	\hline
		\multicolumn{7}{|l|}{4 Processors}\\
	\hline
		100,000			&Average & 0.27690 & 0.19294 & 1.86626 & 1.43515 & 0.14837 \\
		equations		&Minimum & 0.26948 & 0.18933 & 1.59244 & 1.42335 & 0.16922 \\
						&Maximum & 0.28782 & 0.19614 & 2.15375 & 1.46745 & 0.13364 \\
	\hline
		1,000,000		&Average & 3.07809 & 2.38844 & 14.7880 & 1.28875 & 0.20815 \\
		equations		&Minimum & 2.98883 & 2.35483 & 13.2876 & 1.26923 & 0.22493 \\
						&Maximum & 3.15854 & 2.44491 & 18.4698 & 1.29188 & 0.17101 \\
	\hline
		10,000,000		&Average & 33.0215 & 24.6116 & 108.760 & 1.34171 & 0.30362 \\
		equations		&Minimum & 31.5646 & 24.4134 & 107.118 & 1.29292 & 0.29467 \\
						&Maximum & 35.1871 & 24.7888 & 109.561 & 1.41947 & 0.32116 \\
	\hline
		\multicolumn{7}{|l|}{16 Processors}\\
	\hline
		100,000			&Average & 0.58371 & 0.51138 & 3.23072 & 1.15766 & 0.18068 \\
		equations		&Minimum & 0.54744 & 0.49328 & 2.99947 & 1.10979 & 0.18251 \\
						&Maximum & 0.60776 & 0.51907 & 3.47056 & 1.17086 & 0.17512 \\
	\hline
		1,000,000		&Average & 7.46367 & 7.39699 & 21.5343 & 1.00901 & 0.34659 \\
		equations		&Minimum & 7.36098 & 7.32456 & 20.0884 & 1.00497 & 0.36643 \\
						&Maximum & 7.59598 & 7.48964 & 22.8655 & 1.01420 & 0.33220 \\
	\hline
		10,000,000		&Average & 74.6001 & 73.6360 & 151.184 & 1.01310 & 0.49344 \\
		equations		&Minimum & 73.7350 & 73.4646 & 150.411 & 1.00368 & 0.49022 \\
						&Maximum & 74.9087 & 73.8342 & 152.033 & 1.01455 & 0.49271 \\
	\hline
			\multicolumn{7}{|l|}{20 Processors}\\
	\hline
		100,000			&Average & 0.73843 & 0.70837 & 3.14911 & 1.04244 & 0.23449 \\
		equations		&Minimum & 0.73621 & 0.69428 & 2.90237 & 1.06039 & 0.25366 \\
						&Maximum & 0.73967 & 0.71449 & 3.64133 & 1.03524 & 0.20313 \\
	\hline
		1,000,000		&Average & 9.19411 & 9.18584 & 23.2980 & 1.00090 & 0.39463 \\
		equations		&Minimum & 9.14960 & 9.16630 & 22.7740 & 0.99814 & 0.40177 \\
						&Maximum & 9.22002 & 9.21510 & 24.6296 & 1.00053 & 0.37435 \\
	\hline
		10,000,000		&Average & 92.0613 & 91.6512 & 174.402 & 1.00447 & 0.52786 \\
		equations		&Minimum & 91.5029 & 91.2491 & 173.480 & 1.00278 & 0.52746 \\
						&Maximum & 92.5630 & 91.7905 & 175.096 & 1.00842 & 0.52864 \\
	\hline
\end{tabular}

\caption{Timing results of various power method implementations.  All times are in seconds.}
\label{tab:timing-results}
\end{table}

The timing results can be seen in Table~\ref{tab:timing-results}.
The timings were obtained from implementations of the power method for finding the largest eigenvalue of a matrix.
The matrices used were symmetric tridiagonal matrices with the diagonal containing 2's
and the off diagonals containing -1's.
%TODO is there a name for this matrix?
\cite{PowerMethod}
This tests the performance of dot product, L2-norm and sparse matrix-vector multiplication functionalities.
As can be seen in the results table, JuliaPetra is very close to the performance
of Epetra for large problem sizes.
Additionally, JuliaPetra is able to significantly outperform DistributedArrays.jl, performing in less than
half the time of DistributedArrays.jl for all but the largest problems.

The timings were obtained by running each power method implementations
with various sized problems and varying numbers of processors.
Each combination of implementation, problem size and number of processors was run five times
and the average, minimum and maximum are presented.
The Julia implementations were run once before collecting the timings, to ensure all code was
compiled before the timing started.
The Julia tests were run with Julia v0.6.0 precompiled binary for Linux
with the \juliaSnippet{-O3} flag enabled at run time.
The Epetra tests were compiled with GCC 4.8.5, the \juliaSnippet{-O3} flag and Trilinos 12.10.1.
Tests were run on a Red Hat Enterprise Linux Workstation, version 7.3,
with 20 Intel Xeon CPUs.
%TODO anything else that should be described?


\section{Conclusion}

JuliaPetra is an implementation of the Petra object model in the Julia programming language.
This provides a set of basic, distributed linear algebra objects for building solvers in Julia.
JuliaPetra is able to perform at the same speeds as Epetra,
allowing Julia to compete with C++ for these types of high performance computations.

\bibliography{bibliography}
\end{document}