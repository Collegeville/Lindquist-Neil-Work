operations
	4x access struct field
	2x store local_int_t to counter
	1x subtract
	1x load local_int_t
	loop nrow times:
		1x compare counter, const
		1x compare counter, 0
		1x incr counter
		1x decr counter
		14x index array
		6x access struct field
		4x store <datatype> to acumulator
		2x load <datatype> from accumulator
		2x store int to counter
		2x mult
		2x add
		2x divide
		6x load pointer
		2x load int
		6x load <datatype>
		2x store <datatype>
		
	loop nnz times:
		2x compare counter, const
		2x incr counter
		6x index array
		2x mult
		2x subtract
		2x load <datatype> from accumulator
		2x store <datatype> to accumulator
		2x load local_int_t
		2x load <datatype>
		2x load <datatype> poorly cached
			
			
bytes loaded (excluding counters and accumulators, assuming all pointers are the same size)
	well cached:
		sizeof(local_int_t)
		+ nrow*(6*sizeof(void*) + 2*sizeof(int) + 6*sizeof(<datatype>))
		+ nnz*(2*sizeof(local_int_t) + 2*sizeof(<datatype>))
	poorly cached:
		nnz*2*sizeof(<datatype>)
		

	calculated for actual setup (sizeof(void*) -> 8 bytes, sizeof(local_int_t) -> sizeof(int) -> 4 bytes)
		well cached:
			4 + nrow*(56 + 6*sizeof(<datatype>)) + nnz*(8 + 2*sizeof(<datatype>))
		poorly cached:
			nnz*2*sizeof(<datatype>)
			
		
		with 32-bit floats
			well cached:
				4 + nrow*(80) + nnz*(16)
				≈ 4 + (248/13)*nnz
				≈ 19.08*nnz
			poorly cached:
				8*nnz
				
			
		with 64-bit floats
			well cached:
				4 + nrow*(104) + nnz*(24)
				≈ 4 + 28*nnz
				≈ 28*nnz
			poorly cached:
				nnz*(16)
			
		theoretical  - 31.87% decrease in well cached bytes
					   50% decrease in poorly cached bytes (NOTE: 0% decrease in number of values fetched)
		
		
		
		
bytes stored (excluding counters and accumulators)
	nrow * 2 * sizeof(<datatype>)
	
	with 32 bit float
		8 * nrow
	with 64 bit float
		16 * nrow
		
	theoretical  - 50% decrease
